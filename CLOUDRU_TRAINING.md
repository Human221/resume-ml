# –ü–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ Cloud.ru

## üéØ –¶–µ–ª—å
–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ Hugging Face `evilfreelancer/headhunter` –∏—Å–ø–æ–ª—å–∑—É—è GPU –º–æ—â–Ω–æ—Å—Ç–∏ Cloud.ru.

---

## üìã –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ Cloud.ru

### 1.1. –°–æ–∑–¥–∞–π—Ç–µ GPU –∏–Ω—Å—Ç–∞–Ω—Å

1. –í–æ–π–¥–∏—Ç–µ –≤ –ø–∞–Ω–µ–ª—å Cloud.ru
2. –°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—É—é –º–∞—à–∏–Ω—É —Å GPU:
   - **–û–°**: Ubuntu 22.04 –∏–ª–∏ 20.04
   - **GPU**: –í—ã–±–µ—Ä–∏—Ç–µ GPU —Å –º–∏–Ω–∏–º—É–º 16GB –ø–∞–º—è—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, NVIDIA A100, V100)
   - **RAM**: –ú–∏–Ω–∏–º—É–º 32GB
   - **–î–∏—Å–∫**: –ú–∏–Ω–∏–º—É–º 100GB

### 1.2. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ –∏–Ω—Å—Ç–∞–Ω—Å—É

```bash
ssh –≤–∞—à_–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å@ip_–∞–¥—Ä–µ—Å_–∏–Ω—Å—Ç–∞–Ω—Å–∞
```

---

## üì¶ –®–∞–≥ 2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

### 2.1. –û–±–Ω–æ–≤–∏—Ç–µ —Å–∏—Å—Ç–µ–º—É

```bash
sudo apt update
sudo apt upgrade -y
```

### 2.2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Python –∏ pip

```bash
sudo apt install -y python3.10 python3-pip python3-venv
```

### 2.3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA (–µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞)

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ CUDA:
```bash
nvidia-smi
```

–ï—Å–ª–∏ CUDA –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, —Å–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º Cloud.ru –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ CUDA –Ω–∞ –≤–∞—à–µ–º –∏–Ω—Å—Ç–∞–Ω—Å–µ.

### 2.4. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

```bash
# –ï—Å–ª–∏ –∫–æ–¥ —É–∂–µ –≤ Git
git clone https://github.com/Human221/resume-ml.git
cd resume-ml

# –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã —á–µ—Ä–µ–∑ scp —Å –≤–∞—à–µ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞:
# scp -r /Users/rustam/Desktop/resume-ml –≤–∞—à_–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å@ip_–∞–¥—Ä–µ—Å:/home/–≤–∞—à_–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å/
```

### 2.5. –°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2.6. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA (–≤–∞–∂–Ω–æ!)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install -r requirements-train.txt
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏:**
```bash
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\"}')"
```

---

## üîç –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞

### 3.1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞

```bash
python download_hf_dataset.py --dataset evilfreelancer/headhunter --action list
```

–î–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö splits (train, test, validation –∏ —Ç.–¥.)

### 3.2. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ–±—Ä–∞–∑—Ü—ã –¥–∞–Ω–Ω—ã—Ö

```bash
python download_hf_dataset.py --dataset evilfreelancer/headhunter --action sample --num-samples 5
```

–≠—Ç–æ –ø–æ–∫–∞–∂–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–º–µ—Ä—ã –≤–∞–∫–∞–Ω—Å–∏–π.

---

## üöÄ –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### 4.1. –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–Ω–∞—á–∞–ª–∞)

–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–π –≤—ã–±–æ—Ä–∫–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

```bash
python train_model.py \
    --model-name IlyaGusev/saiga_mistral_7b_merged \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --hf-split train \
    --output-dir ./models/finetuned \
    --num-epochs 1 \
    --batch-size 2 \
    --max-samples 100 \
    --learning-rate 2e-5
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞:**
- `--max-samples 100` - —Ç–æ–ª—å–∫–æ 100 –ø—Ä–∏–º–µ—Ä–æ–≤ (–±—ã—Å—Ç—Ä–æ)
- `--num-epochs 1` - –æ–¥–Ω–∞ —ç–ø–æ—Ö–∞
- `--batch-size 2` - –º–∞–ª–µ–Ω—å–∫–∏–π –±–∞—Ç—á (–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –ø–∞–º—è—Ç–∏)

### 4.2. –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:

```bash
python train_model.py \
    --model-name IlyaGusev/saiga_mistral_7b_merged \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --hf-split train \
    --output-dir ./models/finetuned \
    --num-epochs 3 \
    --batch-size 4 \
    --learning-rate 2e-5 \
    --max-length 512
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:**
- –£–±—Ä–∞–Ω–æ `--max-samples` - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç
- `--num-epochs 3` - 3 —ç–ø–æ—Ö–∏
- `--batch-size 4` - –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–æ 8, –µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å

### 4.3. –û–±—É—á–µ–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ (–¥–ª—è –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤)

–ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–π–º–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ñ–æ–Ω–µ:

```bash
# –ó–∞–ø—É—Å–∫ –≤ screen (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
screen -S training
python train_model.py \
    --model-name IlyaGusev/saiga_mistral_7b_merged \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --output-dir ./models/finetuned \
    --num-epochs 3 \
    --batch-size 4

# –û—Ç–∫–ª—é—á–∏—Ç—å—Å—è –æ—Ç screen: Ctrl+A, –∑–∞—Ç–µ–º D
# –í–µ—Ä–Ω—É—Ç—å—Å—è: screen -r training
```

–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `nohup`:

```bash
nohup python train_model.py \
    --model-name IlyaGusev/saiga_mistral_7b_merged \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --output-dir ./models/finetuned \
    --num-epochs 3 \
    --batch-size 4 \
    > training.log 2>&1 &

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
tail -f training.log
```

---

## üìä –®–∞–≥ 5: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è

### 5.1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU

–í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ:
```bash
watch -n 1 nvidia-smi
```

### 5.2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤

```bash
# –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ nohup
tail -f training.log

# –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ screen
screen -r training
```

### 5.3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤

```bash
ls -lh ./models/finetuned/checkpoint-*/
```

---

## ‚úÖ –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è:

### 6.1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å

```bash
ls -lh ./models/finetuned/
```

–î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ñ–∞–π–ª—ã:
- `config.json`
- `pytorch_model.bin` –∏–ª–∏ `model.safetensors`
- `tokenizer.json`
- –∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞

### 6.2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç:

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_path = "./models/finetuned"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path)

# –¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
prompt = "<|im_start|>system\n–¢—ã - HR-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.<|im_end|>\n<|im_start|>user\n–û–ø–∏—à–∏ –≤–∞–∫–∞–Ω—Å–∏—é Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞<|im_end|>\n<|im_start|>assistant\n"

inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=200, temperature=0.7)
response = tokenizer.decode(outputs[0], skip_special_tokens=False)
print(response)
```

---

## üíæ –®–∞–≥ 7: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

### 7.1. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä

```bash
# –° –≤–∞—à–µ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞
scp -r –≤–∞—à_–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å@ip_–∞–¥—Ä–µ—Å:/home/–≤–∞—à_–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å/resume-ml/models/finetuned ./models/
```

### 7.2. –ò–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –≤ –æ–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ Cloud.ru

–°–ª–µ–¥—É–π—Ç–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º Cloud.ru –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –≤ Object Storage.

---

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–¥ –≤–∞—à GPU

### –î–ª—è GPU —Å 16GB –ø–∞–º—è—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, NVIDIA T4, RTX 3090)

```bash
python train_model.py \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --batch-size 2 \
    --gradient-accumulation-steps 8 \
    --num-epochs 3
```

### –î–ª—è GPU —Å 24GB+ –ø–∞–º—è—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, NVIDIA A100, RTX 4090)

```bash
python train_model.py \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --batch-size 4 \
    --gradient-accumulation-steps 4 \
    --num-epochs 3
```

### –î–ª—è GPU —Å 40GB+ –ø–∞–º—è—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, NVIDIA A100 40GB)

```bash
python train_model.py \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --batch-size 8 \
    --gradient-accumulation-steps 2 \
    --num-epochs 3
```

---

## ‚ö†Ô∏è Troubleshooting

### –û—à–∏–±–∫–∞: "Out of memory"

–£–º–µ–Ω—å—à–∏—Ç–µ `--batch-size`:
```bash
--batch-size 1  # –≤–º–µ—Å—Ç–æ 4
```

–ò–ª–∏ —É–≤–µ–ª–∏—á—å—Ç–µ `--gradient-accumulation-steps` –≤ –∫–æ–¥–µ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å `train_model.py`).

### –û—à–∏–±–∫–∞: "CUDA not available"

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:
```bash
nvidia-smi
python3 -c "import torch; print(torch.cuda.is_available())"
```

–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω PyTorch —Å CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π.

### –û—à–∏–±–∫–∞: "Dataset not found"

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Hugging Face:
```bash
curl https://huggingface.co/datasets/evilfreelancer/headhunter
```

### –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

- –£–≤–µ–ª–∏—á—å—Ç–µ `--batch-size` –µ—Å–ª–∏ –µ—Å—Ç—å —Å–≤–æ–±–æ–¥–Ω–∞—è –ø–∞–º—è—Ç—å
- –£–º–µ–Ω—å—à–∏—Ç–µ `--max-length` (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–æ 256)
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `--max-samples` –¥–ª—è —Ç–µ—Å—Ç–∞ –Ω–∞ –º–µ–Ω—å—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ

---

## üìù –ü—Ä–∏–º–µ—Ä –ø–æ–ª–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –∑–∞–ø—É—Å–∫–∞

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `train.sh`:

```bash
#!/bin/bash

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è
source venv/bin/activate

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
python train_model.py \
    --model-name IlyaGusev/saiga_mistral_7b_merged \
    --use-hf \
    --hf-dataset evilfreelancer/headhunter \
    --hf-split train \
    --output-dir ./models/finetuned \
    --num-epochs 3 \
    --batch-size 4 \
    --learning-rate 2e-5 \
    --max-length 512

echo "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
```

–°–¥–µ–ª–∞–π—Ç–µ –∏—Å–ø–æ–ª–Ω—è–µ–º—ã–º –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:
```bash
chmod +x train.sh
./train.sh
```

---

## üéì –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [TRAINING.md](TRAINING.md) - –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –æ–±—É—á–µ–Ω–∏—é
- [HUGGINGFACE_GUIDE.md](HUGGINGFACE_GUIDE.md) - –†–∞–±–æ—Ç–∞ —Å Hugging Face
- [README.md](README.md) - –û–±—â–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞

---

## ‚è±Ô∏è –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—É—á–µ–Ω–∏—è

- **–¢–µ—Å—Ç (100 –ø—Ä–∏–º–µ—Ä–æ–≤, 1 —ç–ø–æ—Ö–∞)**: ~10-30 –º–∏–Ω—É—Ç
- **–ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–≤–µ—Å—å –¥–∞—Ç–∞—Å–µ—Ç, 3 —ç–ø–æ—Ö–∏)**: 
  - –ù–∞ GPU 16GB: ~4-8 —á–∞—Å–æ–≤
  - –ù–∞ GPU 24GB: ~2-4 —á–∞—Å–∞
  - –ù–∞ GPU 40GB+: ~1-2 —á–∞—Å–∞

*–í—Ä–µ–º—è –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –º–æ—â–Ω–æ—Å—Ç–∏ GPU*

